<html>
    <head>
    <title>SET!</title>
    <style>
    body {font-family: serif;}
    .center {
        margin: auto;
        width: 700px;
        padding: 0px;
    }
    </style>
    </head>
    <body>
    <div class="center">
        <h1 style="text-align:center; margin-bottom:10px">Playing SET with OpenCV and YOLOv5</h1>
        <img align="left" src="set-game-files/topimage.png" style="display:block; margin-left:50px", width="600">
        <p style="clear:left; width: 700px;">
            <br>
            How to play the game: 
            <br>
            <br>
            The objective is to find sets from a group of 12~15 cards as quickly as possible. A set consists of three cards such that the four attributes: color, shape, count, and fill, are either the same for all three cards, or are all different. <br>
            <br>
            Examples: <br>
        </p>
        <img align=left src="set-game-files/examples.png" style="display:block", width="700">
        <p style="clear:left; width: 700px;">
            <br>
            The three cards on the left form a set, since they all have different colors, shapes, counts and fills. The ones in the middle also form a set, since they all have the same color and count, and all different shapes and fills. However, the cards on the right do NOT a form set, since they do not <i>all</i> have the same or all different fills - although they have different shapes, colors, and counts, there are two striped cards and a solid card.
        </p>
        <p style="clear:left; width: 700px;">
            See also: <a href="set-game-files/setinstructions.pdf" target="_blank" rel="noopener noreferrer">
                set instructions
            </a>
        </p>
        <hr style="width:700px;text-align:left;margin-left:0">
        <p style="clear:left; width: 700px;">
            To get the computer to play, it first needs to identify the cards. I originally tried to do this without machine learning - training would require me to take thousands of pictures and label them, is what I figured, then, and I didn't want to do that! So I used OpenCV to first segment an image into individual cards, warp the card so that they was flat (birds-eye view), and identify each of the four features, using the following methods: <br>
            <br>
            Count: find contours on each card, count contours that are approximately the same size as the largest<br>
            Shape: take the absolute difference with pre-drawn shape masks, find shape with minimum difference <br>
            Color: average the hue over the shape mask, eyeball it with hardcoded values for red/green/purple<br>
            Fill: find percent of non-white pixels in the inside of shape mask<br>
            <br>
            As you can see below, it's pretty spotty, even with high contrast and no overlap:
            <br>
        </p>
        <img align="left" src="set-game-files/badgood.png" style="display:block", width="700">
        <p style="clear:left; width: 700px;">
            <br>
            If you're interested, which you shouldn't be - the pictures above should serve as an anti-advertisement,
            here is the code: 
            <a href="set-game-files/originalattempt.py" download>
              originalattempt.py</a><br>
        </p>
        <hr style="width:700px;text-align:left;margin-left:0">
        <p style="clear:left; width: 700px;">
            I caved and went with the machine learning route. <br>
            <br>
            To avoid taking thousands of pictures, what I ended up doing was taking 7 pictures of all 81 cards, repurposing the code above to cut each of the 81 cards from the pictures, and hand-labelling 81x7=567 cards. Here's a sample of those labelled cards:<br>
        </p>
        <img align="left" src="set-game-files/fileexplorerimage.JPG" style="display:block", width="700">
        <p style="clear:left; width: 700px;">
            <br>
            Then I went around my apartment and took a bunch of pictures of various surfaces and clutter to use as backgrounds, which I augmented and cropped into squares. For each of 20,000 generated images, I took a random background, picked 4 random cards, and placed them in 'random' positions (it wasn't exactly random - I had to make sure that the cards didn't <i>completely</i> cover each other). Using imgaug, I then changed perspective, zoom, rotation, coloration, noise, etc... and voil&aacute;! 80,000 cards! <br>
            <br>
            Here's the code for generating the data: <a href="set-game-files/generatedata.py" download>
              generatedata.py</a><br>
            <br>
            A snippet of the generated data - click for full-sized image:<br>
        </p>
        <a href="set-game-files/sampling.jpg" target="_blank" rel="noopener noreferrer">
            <img align="left" target="_blank" src="set-game-files/sampling.jpg" style="display:block", width="700">
        </a>
        <p style="clear:left; width: 700px;">
            <br>
            And if for whatever reason you want the whole dataset, here's the dropbox link to the .tar file:
            <a href="https://www.dropbox.com/s/66oyk8y65ndpamc/datasets.tar?dl=0" target="_blank" rel="noopener noreferrer">
                dataset</a><br>
            <br>
            To avoid false positives, I put in a bunch of junk photos, along with some things that might be confused as cards, such as the coco 128 dataset + background images without cards + pictures of poker cards + pictures of sticky notes + phones + index cards + colored pills + paint splotches + etc... <br>
            <br>
            I trained for 50 epochs using YOLOv5's pretrained medium-sized network. I ended up using YOLOv5 since they have a notebook written for Colab - I couldn't get the other versions to run locally on my Windows laptop :( )<br>
            <br>
            Here are the training results - click for full-sized image:<br>
        </p>
        <a href="set-game-files/results.png" target="_blank" rel="noopener noreferrer">
            <img align="left" src="set-game-files/results.png" style="display:block", width="700">
        </a>
        <p style="clear:left; width: 700px;">
            <br>
            It's does reasonably well! Although something that might help to do in the future would be to simply run more epochs; it seems like the mAP hasn't yet completely plateaued. But I was happy with it as it was.
        </p>
        <hr style="clear:left; width:700px;text-align:left;margin-left:0">
        <p style="clear:left; width: 700px;">
            After training, all that's left is to write the set algorithm. There's a clever way to determine if any given collection of 3 cards is a set: if we assign each type in an attribute a number from &#123;0,1,2&#125; - for example, squiggle=0, diamond=1, oval=2, the sum for each attribute over the three cards should equal 0 mod 3.<br>
            <br>
            Read &#167;3 of this paper for a better explanation: <a href="http://web.math.princeton.edu/~charchan/SET.pdf" target="_blank" rel="noopener noreferrer">set math</a>, or just read the whole thing!<br>
            <br>
            The detections were sometimes unstable - they tend to flicker as the lighting changes. To fix that, I made a queue of recent set detections from the previous 30 frames and displayed the mode. I also sorted the sets, so that when multiple sets exist in the deck, it picks one consistently; otherwise it switches back and forth between them. Something that might be nice to implement later would be to draw borders on the contours of the cards, as in the original attempt, instead of bounding boxes, but I couldn't get YOLOv5 to do that. It seems for now the only annotation format YOLOv5 supports is bounding boxes.<br>
            <br>
            Here's a video of it in action:
            <br>
        </p>
        <video width="700" controls>
            <source src="set-game-files/demovideo.mp4" type="video/mp4">
            Your browser does not support HTML video.
        </video>
        <p style="clear:left; width: 700px;">
            Note how it handles rotation and overlapping cards! It also ignores cards that aren't set cards.<br>
            <br>
            If you would like to run it, here is the detection code modified for finding sets, and the trained weights:<br>
            <br>
            Set detection: <a href="set-game-files/detectsets.py" download>
              detectsets.py</a><br>
            Weights: <a href="set-game-files/setcardsweights.pt" download>
              setcardsweights.pt
            </a><br>
            <br>
            Copy these into the yolov5 folder, and run with:<br>
            <br>
            <code>python detectsets.py --source 1 --weights setcardsweights.pt --conf-thres 0.5</code><br>
            <br>
            Hooray!<br>
            <br>
        </p>
        <hr>
        <footer>
            <p>
                (casey's cse 455 final project)<br>
                czhao4 (at) uw (dot) edu
            </p>
        </footer>
        </div>
    </body>
</html>
